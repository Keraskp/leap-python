## Mainstream ML  Models
- SVM - **COMPLETED** 96.39 %
- Decision Tree **COMPLETED** 93.70%
- Gaussian Naive Bayes - **COMPLETED** 41.01%
- KNN (K-Nearest Neighbours) - **COMPLETED** 98.81% for k = 2 or 3 and 97.90% for k = 5 or 7
- Neural Networks (MLP) - **COMPLETED** 99.24%

## Ensembles:
- AdaBoost Classifier - 
- Bagging Classifier - 
- Extra Trees Classifier - 
- Gradient Boosting Classifier - 
- Random Forest Classifier - 
- Voting Classifier - 
- Stacking Classifier -
- Hist Gradient Boosting Classifier -  

- XGBoosted Trees

- Logistic regression 1 vs all

# Important Metrics
- Loss
- Training Accuracy
- Validation Accuracy
- Loss (test)
- Accuracy (test)
- Confusion Matrix
- Precision
- Recall
- F1 Score
- ROC
- AOC
- Cohen's kapppa (Optional)

# 09/11/2023
- Find and Apply all possible classification models in Python 2.7
- Create a new Balanced Dataset
- Look for all the metrics that have to show in results 
- Retrain all models with Hyperparameter tuning and Grid Search CV


